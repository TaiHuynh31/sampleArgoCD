apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: iris-training-pipeline-
spec:
  entrypoint: iris-pipeline
  templates:

  # DAG định nghĩa toàn bộ pipeline
  - name: iris-pipeline
    dag:
      tasks:
      - name: preprocess
        template: preprocess-op
      - name: train
        template: train-op
        dependencies:
        - preprocess
      - name: evaluate
        template: evaluate-op
        dependencies:
        - preprocess
        - train

  # Template cho bước Preprocessing
  - name: preprocess-op
    container:
      image: python:3.9
      command: ["sh", "-c"]
      args:
      - |
        python3 -m ensurepip || python3 -m ensurepip --user
        pip install --quiet scikit-learn numpy
        python -c "
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np
import os
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
os.makedirs('/data/output', exist_ok=True)
np.save('/data/output/X_train.npy', X_train)
np.save('/data/output/y_train.npy', y_train)
np.save('/data/output/X_test.npy', X_test)
np.save('/data/output/y_test.npy', y_test)
        "
      volumeMounts:
      - name: data-volume
        mountPath: /data

  # Template cho bước Training
  - name: train-op
    container:
      image: python:3.9
      command: ["sh", "-c"]
      args:
      - |
        python3 -m ensurepip || python3 -m ensurepip --user
        pip install --quiet tensorflow numpy
        python -c "
import tensorflow as tf
import numpy as np
import os
X_train = np.load('/data/output/X_train.npy')
y_train = np.load('/data/output/y_train.npy')
model = tf.keras.Sequential([
    tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=10, batch_size=8)
os.makedirs('/data/model', exist_ok=True)
model.save('/data/model/iris_model.h5')
        "
      volumeMounts:
      - name: data-volume
        mountPath: /data

  # Template cho bước Evaluation
  - name: evaluate-op
    container:
      image: python:3.9
      command: ["sh", "-c"]
      args:
      - |
        python3 -m ensurepip || python3 -m ensurepip --user
        pip install --quiet tensorflow numpy scikit-learn
        python -c "
import tensorflow as tf
import numpy as np
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
X_test = np.load('/data/output/X_test.npy')
y_test = np.load('/data/output/y_test.npy')
model = tf.keras.models.load_model('/data/model/iris_model.h5')
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
accuracy = accuracy_score(y_test, y_pred_classes)
precision = precision_score(y_test, y_pred_classes, average='weighted')
recall = recall_score(y_test, y_pred_classes, average='weighted')
f1 = f1_score(y_test, y_pred_classes, average='weighted')
print(f'Accuracy: {accuracy:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
        "
      volumeMounts:
      - name: data-volume
        mountPath: /data

  # Volume để chia sẻ dữ liệu giữa các bước
  volumes:
  - name: data-volume
    emptyDir: {}
